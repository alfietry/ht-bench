@article{chen2022program,
  title={Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks},
  author={Chen, Wenhu and Ma, Xueguang and Wang, Xinyi and Cohen, William W},
  journal={arXiv preprint arXiv:2211.12588},
  year={2022}
}

@article{russakovsky2015imagenet,
  title={Imagenet large scale visual recognition challenge},
  author={Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and others},
  journal={International journal of computer vision},
  volume={115},
  number={3},
  pages={211--252},
  year={2015},
  publisher={Springer}
}

@book{koslowski1996theory,
  title={Theory and evidence: The development of scientific reasoning},
  author={Koslowski, Barbara},
  year={1996},
  publisher={Mit Press}
}

@book{national2012assessing,
  title={Assessing the reliability of complex models: mathematical and statistical foundations of verification, validation, and uncertainty quantification},
  author={National Research Council and Division on Engineering and Physical Sciences and Board on Mathematical Sciences and Their Applications and Committee on Mathematical Foundations of Verification and Uncertainty Quantification},
  year={2012},
  publisher={National Academies Press}
}

@article{yamada2025ai,
  title={The ai scientist-v2: Workshop-level automated scientific discovery via agentic tree search},
  author={Yamada, Yutaro and Lange, Robert Tjarko and Lu, Cong and Hu, Shengran and Lu, Chris and Foerster, Jakob and Clune, Jeff and Ha, David},
  journal={arXiv preprint arXiv:2504.08066},
  year={2025}
}

@article{bengio2025superintelligent,
  title={Superintelligent agents pose catastrophic risks: Can scientist ai offer a safer path?},
  author={Bengio, Yoshua and Cohen, Michael and Fornasiere, Damiano and Ghosn, Joumana and Greiner, Pietro and MacDermott, Matt and Mindermann, S{\"o}ren and Oberman, Adam and Richardson, Jesse and Richardson, Oliver and others},
  journal={arXiv preprint arXiv:2502.15657},
  year={2025}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Chi, Ed and Le, Quoc and Zhou, Denny},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{chen2022program,
  title={Program of thoughts prompting: Disentangling computation from reasoning for numerical reasoning tasks},
  author={Chen, Wenhu and Ma, Xueguang and Wang, Xinyi and Cohen, William W},
  journal={arXiv preprint arXiv:2211.12588},
  year={2022}
}

@article{srivastava2022beyond,
  title={Beyond the imitation game: Quantifying and extrapolating the capabilities of language models},
  author={Srivastava, Aarohi and Rastogi, Abhinav and Rao, Abhishek and Shoeb, Abu Awal Md and Abid, Abubakar and Fisch, Adam and Brown, Adam R and Santoro, Adam and Gupta, Aditya and Garrido, Adri{\`a} and others},
  journal={arXiv preprint arXiv:2206.04615},
  year={2022}
}

@article{tang2023evaluating,
  title={Evaluating large language models on statistical reasoning},
  author={Tang, L. and others},
  journal={arXiv preprint},
  year={2023}
}

@article{liu2024are,
  title={Are LLMs capable of data-based statistical and causal reasoning? Benchmarking advanced quantitative reasoning with data},
  author={Liu, X. and Wu, Z. and Wu, X. and Lu, P. and Chang, K.-W. and Feng, Y.},
  journal={arXiv preprint arXiv:2402.17644},
  year={2024}
}

@article{zhu2024are,
  title={Are large language models good statisticians?},
  author={Zhu, Y. and Du, S. and Li, B. and Luo, Y. and Tang, N.},
  journal={Advances in Neural Information Processing Systems (NeurIPS)},
  volume={37},
  pages={62697--62731},
  year={2024}
}

@article{tiwari2025framework,
  title={A framework for automated hypothesis testing},
  author={Tiwari, H.},
  journal={Preprint / Technical Report},
  year={2025}
}

@article{parmar2024logicbench,
  title={Logicbench: Towards systematic evaluation of logical reasoning ability of large language models},
  author={Parmar, Mihir and Patel, Nisarg and Varshney, Neeraj and Nakamura, Mutsumi and Luo, Man and Mashetty, Santosh and Mitra, Arindam and Baral, Chitta},
  journal={arXiv preprint arXiv:2404.15522},
  year={2024}
}

@article{zhang2024multilogieval,
  title={Multi-LogiEval: A unified benchmark for multi-step logical reasoning in large language models},
  author={Zhang, S. and others},
  journal={arXiv preprint},
  year={2024}
}

@article{liu2025logical,
  title={Logical reasoning in large language models: A survey},
  author={Liu, Hanmeng and Fu, Zhizhang and Ding, Mengru and Ning, Ruoxi and Zhang, Chaoli and Liu, Xiaozhang and Zhang, Yue},
  journal={arXiv preprint arXiv:2502.09100},
  year={2025}
}

@article{survey2025logical,
  title={Logical reasoning in large language models: A survey},
  author={Survey, Authors},
  journal={arXiv preprint},
  year={2025}
}

@inproceedings{hong2024closer,
  title={A closer look at the self-verification abilities of large language models in logical reasoning},
  author={Hong, W. and others},
  booktitle={Proceedings of NAACL 2024},
  year={2024}
}

@article{jiao2025trustworthy,
  title={Trustworthy reasoning: Evaluating and enhancing factual accuracy in LLM intermediate thought processes},
  author={Jiao, F. and Zhang, W. and Li, X.},
  journal={arXiv preprint},
  year={2025}
}

@article{marinescu2025factreasoner,
  title={FactReasoner: A Probabilistic Approach to Long-Form Factuality Assessment for Large Language Models},
  author={Marinescu, Radu and Bhattacharjya, Debarun and Lee, Junkyu and Tchrakian, Tigran and Cano, Javier Carnerero and Hou, Yufang and Daly, Elizabeth and Pascale, Alessandra},
  journal={arXiv preprint arXiv:2502.18573},
  year={2025}
}

@article{zhu2025factreasoner,
  title={FactReasoner: A probabilistic framework for long-form factuality assessment of large language models},
  author={Zhu, T. and others},
  journal={arXiv preprint},
  year={2025}
}

@article{wang2023scientific,
  title={Scientific discovery in the age of artificial intelligence},
  author={Wang, Hanchen and Fu, Tianfan and Du, Yuanqi and Gao, Wenhao and Huang, Kexin and Liu, Ziming and Chandak, Payal and Liu, Shengchao and Van Katwyk, Peter and Deac, Andreea and others},
  journal={Nature},
  volume={620},
  number={7972},
  pages={47--60},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@article{openai2023gpt,
  title={GPT-4 Technical Report: Tech. Rep.},
  author={OpenAI, N},
  year={2023},
  publisher={OpenAI}
}

@techreport{achiam2023gpt4,
  title={GPT-4 Technical Report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  year={2023},
  institution={OpenAI},
  note={arXiv preprint arXiv:2303.08774}
}

@inproceedings{wan2024logicasker,
  title={LogicAsker: Evaluating and Improving the Logical Reasoning Ability of Large Language Models},
  author={Wan, Y. and others},
  booktitle={Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year={2024}
}

@article{patel2024multi,
  title={Multi-logieval: Towards evaluating multi-step logical reasoning ability of large language models},
  author={Patel, Nisarg and Kulkarni, Mohith and Parmar, Mihir and Budhiraja, Aashna and Nakamura, Mutsumi and Varshney, Neeraj and Baral, Chitta},
  journal={arXiv preprint arXiv:2406.17169},
  year={2024}
}

@article{zhang2024multilogieval,
  title={Multi-LogiEval: A Unified Benchmark for Multi-Step Logical Reasoning in Large Language Models},
  author={Zhang, S. and others},
  journal={arXiv preprint},
  year={2024}
}

@article{survey2025logical,
  title={Logical Reasoning in Large Language Models: A Survey},
  author={Authors, Various},
  journal={arXiv preprint},
  year={2025}
}

@article{zhu2025factreasoner,
  title={FactReasoner: A Probabilistic Framework for Long-Form Factuality Assessment of Large Language Models},
  author={Zhu, T. and others},
  journal={arXiv preprint},
  year={2025}
}

@article{liu2024llms,
  title={Are llms capable of data-based statistical and causal reasoning? benchmarking advanced quantitative reasoning with data},
  author={Liu, Xiao and Wu, Zirui and Wu, Xueqing and Lu, Pan and Chang, Kai-Wei and Feng, Yansong},
  journal={arXiv preprint arXiv:2402.17644},
  year={2024}
}

@article{liu2024are,
  title={Are LLMs Capable of Data-Based Statistical and Causal Reasoning? Benchmarking Advanced Quantitative Reasoning with Data},
  author={Liu, X. and Wu, Z. and Wu, X. and Lu, P. and Chang, K.-W. and Feng, Y.},
  journal={arXiv preprint arXiv:2402.17644},
  year={2024}
}

@article{zhu2024large,
  title={Are large language models good statisticians?},
  author={Zhu, Yizhang and Du, Shiyin and Li, Boyan and Luo, Yuyu and Tang, Nan},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={62697--62731},
  year={2024}
}
